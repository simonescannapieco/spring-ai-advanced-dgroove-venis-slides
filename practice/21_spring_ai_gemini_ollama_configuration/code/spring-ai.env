# MODE:
# "llm-cpu" --> Large Language Model in cpu mode
# "llm-gpu" --> Large Language Model in gpu mode
MODE=llm-cpu                                    
COMPOSE_PROFILES=${MODE}
LOG_LEVEL=WARNING                                                                    # default: WARNING

# Ollama configuration
#OLLAMA_VERSION=0.1.39                                                                # default: latest
OLLAMA_PORT=11434                                                                      # default: 11434
OLLAMA_DEBUG=false                                                                     # default: false
OLLAMA_FLASH_ATTENTION=false                                                           # default: false
OLLAMA_KEEP_ALIVE="5m"                                                                  # default: "5m" 
OLLAMA_MAX_LOADED_MODELS=2                                                                 # default: 1
OLLAMA_NUM_PARALLEL=1                                                                      # default: 1
